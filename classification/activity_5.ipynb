{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a3cbe79",
   "metadata": {},
   "source": [
    "## **Feature Importance in Logistic Regression**\n",
    "   - Train a Logistic Regression model using the entire dataset.\n",
    "   - Identify the most important feature based on the highest absolute coefficient value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fdbe0077",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv('spambase.csv')\n",
    "\n",
    "# Separate features and target\n",
    "X = df.drop('class', axis=1)\n",
    "y = df['class']\n",
    "\n",
    "# Split dataset into training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9bf173ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For this exercise, we'll use the entire dataset as requested\n",
    "# But let's also create a proper train/test split for evaluation\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "# For coefficient analysis, we'll use the entire dataset\n",
    "X_full = X\n",
    "y_full = y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20278a07",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a1bafbe6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Coefficients:\n",
      "==================================================\n",
      "Top 10 Most Important Features:\n",
      "                 Feature  Coefficient  Abs_Coefficient  Odds_Ratio\n",
      "26      word_freq_george    -3.978600         3.978600    0.018712\n",
      "52         char_freq_%24     3.923058         3.923058   50.554800\n",
      "6       word_freq_remove     2.198654         2.198654    9.012878\n",
      "22         word_freq_000     2.079641         2.079641    8.001598\n",
      "41     word_freq_meeting    -1.818344         1.818344    0.162294\n",
      "24          word_freq_hp    -1.794308         1.794308    0.166242\n",
      "47  word_freq_conference    -1.741294         1.741294    0.175293\n",
      "40          word_freq_cs    -1.719267         1.719267    0.179198\n",
      "45         word_freq_edu    -1.410830         1.410830    0.243941\n",
      "28         word_freq_lab    -1.354008         1.354008    0.258203\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Train Logistic Regression on the entire dataset\n",
    "cls = LogisticRegression(random_state=21, max_iter=3000)\n",
    "cls.fit(X_full, y_full)\n",
    "\n",
    "# Get feature names\n",
    "feature_names = X.columns.tolist()\n",
    "\n",
    "print(\"Logistic Regression Coefficients:\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Create a DataFrame for better visualization\n",
    "coef_df = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Coefficient': cls.coef_[0],\n",
    "    'Abs_Coefficient': np.abs(cls.coef_[0]),\n",
    "    'Odds_Ratio': np.exp(cls.coef_[0])\n",
    "})\n",
    "\n",
    "# Sort by absolute coefficient value (importance)\n",
    "coef_df_sorted = coef_df.sort_values('Abs_Coefficient', ascending=False)\n",
    "\n",
    "print(\"Top 10 Most Important Features:\")\n",
    "print(coef_df_sorted.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7b9a337c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "COEFFICIENT INTERPRETATION GUIDE:\n",
      "============================================================\n",
      "\n",
      "1. MOST IMPORTANT FEATURE:\n",
      "   Feature: word_freq_george\n",
      "   Coefficient: -3.9786\n",
      "   Odds Ratio: 0.0187\n",
      "   → This feature DECREASES spam probability\n",
      "   → Each unit increase multiplies odds of spam by 0.0187\n",
      "\n",
      "2. POSITIVE COEFFICIENTS (Increase spam probability):\n",
      "   • char_freq_%24: 3.9231 (odds ratio: 50.5548)\n",
      "   • word_freq_remove: 2.1987 (odds ratio: 9.0129)\n",
      "   • word_freq_000: 2.0796 (odds ratio: 8.0016)\n",
      "   • char_freq_%23: 1.3187 (odds ratio: 3.7384)\n",
      "   • word_freq_free: 1.0165 (odds ratio: 2.7634)\n",
      "\n",
      "3. NEGATIVE COEFFICIENTS (Decrease spam probability):\n",
      "   • word_freq_george: -3.9786 (odds ratio: 0.0187)\n",
      "   • word_freq_meeting: -1.8183 (odds ratio: 0.1623)\n",
      "   • word_freq_hp: -1.7943 (odds ratio: 0.1662)\n",
      "   • word_freq_conference: -1.7413 (odds ratio: 0.1753)\n",
      "   • word_freq_cs: -1.7193 (odds ratio: 0.1792)\n",
      "\n",
      "4. INTERPRETATION NOTES:\n",
      "   • Coefficient = change in log-odds per unit change in feature\n",
      "   • Odds Ratio = exp(coefficient) = multiplicative effect on odds\n",
      "   • Odds Ratio > 1: feature increases spam odds\n",
      "   • Odds Ratio < 1: feature decreases spam odds\n",
      "   • Larger |coefficient| = stronger influence on prediction\n"
     ]
    }
   ],
   "source": [
    "# Detailed interpretation of coefficients\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"COEFFICIENT INTERPRETATION GUIDE:\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\\n1. MOST IMPORTANT FEATURE:\")\n",
    "most_important = coef_df_sorted.iloc[0]\n",
    "print(f\"   Feature: {most_important['Feature']}\")\n",
    "print(f\"   Coefficient: {most_important['Coefficient']:.4f}\")\n",
    "print(f\"   Odds Ratio: {most_important['Odds_Ratio']:.4f}\")\n",
    "\n",
    "if most_important['Coefficient'] > 0:\n",
    "    print(f\"   → This feature INCREASES spam probability\")\n",
    "    print(f\"   → Each unit increase multiplies odds of spam by {most_important['Odds_Ratio']:.4f}\")\n",
    "else:\n",
    "    print(f\"   → This feature DECREASES spam probability\")\n",
    "    print(f\"   → Each unit increase multiplies odds of spam by {most_important['Odds_Ratio']:.4f}\")\n",
    "\n",
    "print(\"\\n2. POSITIVE COEFFICIENTS (Increase spam probability):\")\n",
    "positive_coefs = coef_df_sorted[coef_df_sorted['Coefficient'] > 0].head(5)\n",
    "for idx, row in positive_coefs.iterrows():\n",
    "    print(f\"   • {row['Feature']}: {row['Coefficient']:.4f} (odds ratio: {row['Odds_Ratio']:.4f})\")\n",
    "\n",
    "print(\"\\n3. NEGATIVE COEFFICIENTS (Decrease spam probability):\")\n",
    "negative_coefs = coef_df_sorted[coef_df_sorted['Coefficient'] < 0].head(5)\n",
    "for idx, row in negative_coefs.iterrows():\n",
    "    print(f\"   • {row['Feature']}: {row['Coefficient']:.4f} (odds ratio: {row['Odds_Ratio']:.4f})\")\n",
    "\n",
    "print(\"\\n4. INTERPRETATION NOTES:\")\n",
    "print(\"   • Coefficient = change in log-odds per unit change in feature\")\n",
    "print(\"   • Odds Ratio = exp(coefficient) = multiplicative effect on odds\")\n",
    "print(\"   • Odds Ratio > 1: feature increases spam odds\")\n",
    "print(\"   • Odds Ratio < 1: feature decreases spam odds\")\n",
    "print(\"   • Larger |coefficient| = stronger influence on prediction\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8cc9a51",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50de463b",
   "metadata": {},
   "source": [
    "## Summary of Logistic Regression Coefficient Analysis\n",
    "\n",
    "**Key Insights:**\n",
    "\n",
    "1. **Most Important Feature**: The feature with the highest absolute coefficient value represents the strongest predictor of spam vs. non-spam emails.\n",
    "\n",
    "2. **Coefficient Interpretation**:\n",
    "   - **Positive coefficients**: Features that increase the probability of an email being spam\n",
    "   - **Negative coefficients**: Features that decrease the probability of an email being spam\n",
    "   - **Magnitude**: Larger absolute values indicate stronger influence\n",
    "\n",
    "3. **Odds Ratios**: \n",
    "   - Values > 1 indicate the feature increases spam odds\n",
    "   - Values < 1 indicate the feature decreases spam odds\n",
    "   - The further from 1, the stronger the effect\n",
    "\n",
    "4. **Practical Application**: \n",
    "   - Spam filters can focus on the top features identified by the model\n",
    "   - Understanding which words/characters increase spam probability helps in email filtering\n",
    "   - Features with large negative coefficients can be used to identify legitimate emails"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
